{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iko-ai/ibibio-tts/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "519BayIw16w9",
        "outputId": "855ddd04-d686-49a9-b918-a3ec3a2bdb94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "CV6hrveq2eyI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/drive/MyDrive/dataset/wav_split/wavs\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diC0lprL5UcB",
        "outputId": "3af8083e-e826-4805-ccdc-669dcf13059a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "input_excel_path = '/content/metadata.xlsx'\n",
        "output_csv_path = '/content/drive/MyDrive/dataset/metadata.csv'\n",
        "\n",
        "# Read the Excel file\n",
        "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
        "\n",
        "# Save the dataframe as a CSV file\n",
        "df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Excel file has been successfully converted to CSV.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Xl15zB4vSr",
        "outputId": "e67949ef-48a7-4ac7-e828-1d5e301d5c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel file has been successfully converted to CSV.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "input_csv_path = '/content/drive/MyDrive/dataset/metadata.csv'\n",
        "input_wavs_dir = '/content/drive/MyDrive/dataset/wav'\n",
        "output_dir = '/content/drive/MyDrive/dataset/wav_split'\n",
        "train_output_path = os.path.join(output_dir, 'train.txt')\n",
        "val_output_path = os.path.join(output_dir, 'val.txt')"
      ],
      "metadata": {
        "id": "a5kFSaG65nPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTiaR2j4vs2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Read the input CSV\n",
        "with open(input_csv_path, 'r') as csv_file:\n",
        "    reader = csv.DictReader(csv_file)\n",
        "    data = list(reader)\n",
        "\n",
        "# Shuffle the data\n",
        "random.shuffle(data)\n",
        "\n",
        "# Split the data into 80% training and 20% validation\n",
        "split_index = int(0.8 * len(data))\n",
        "train_data = data[:split_index]\n",
        "val_data = data[split_index:]\n",
        "\n",
        "# Function to write data to a text file\n",
        "def write_data(file_path, data):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for row in data:\n",
        "            # Extract just the filename from the full file path\n",
        "            filename = os.path.basename(row['Filepath'])\n",
        "            transcription = row['Transcription']\n",
        "            file.write(f\"wavs/{filename}|{transcription}\\n\")"
      ],
      "metadata": {
        "id": "SrqJKEJs2NA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the training and validation data to their respective files\n",
        "write_data(train_output_path, train_data)\n",
        "write_data(val_output_path, val_data)"
      ],
      "metadata": {
        "id": "AvpNLDAn5rSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/iko-ai/ibibio-tts.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuIFNM9D5tC5",
        "outputId": "9dc5baff-bf92-40ed-d3f8-6005502113a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ibibio-tts'...\n",
            "remote: Enumerating objects: 16674, done.\u001b[K\n",
            "remote: Counting objects: 100% (443/443), done.\u001b[K\n",
            "remote: Compressing objects: 100% (230/230), done.\u001b[K\n",
            "remote: Total 16674 (delta 248), reused 370 (delta 212), pack-reused 16231\u001b[K\n",
            "Receiving objects: 100% (16674/16674), 12.17 MiB | 16.96 MiB/s, done.\n",
            "Resolving deltas: 100% (13361/13361), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd ../"
      ],
      "metadata": {
        "id": "Euf_Uq4yJ7C-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd ibibio-texttospeech/codes\n",
        "#%cd codes\n",
        "%cd /content/ibibio-tts/codes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg4QnjEu6Ngz",
        "outputId": "eaa2cef8-8155-41fb-eacb-57ed594e32ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ibibio-tts/codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "eglZJBwB1Sx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.laxed.txt"
      ],
      "metadata": {
        "id": "QwsDLpEm6Swl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/Gatozu35/tortoise-tts/resolve/main/dvae.pth -O /content/ibibio-tts/experiments/dvae.pth\n",
        "!wget https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth -O /content/ibibio-tts/experiments/autoregressive.pth"
      ],
      "metadata": {
        "id": "qixhVDpCPilC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ac020f-cad4-433c-c14e-4e08f47f234b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-06 23:23:35--  https://huggingface.co/Gatozu35/tortoise-tts/resolve/main/dvae.pth\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.55, 18.164.174.118, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/9f/83/9f8300e5ccd418d283e72c07d1851f269dbd2ca7bae49cee21285965d9bebe14/a990825371506c16bcf0e8167bf24ccf82f65bb6a1dbcbfcf058d76f9b197e35?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27dvae.pth%3B+filename%3D%22dvae.pth%22%3B&Expires=1717975415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzk3NTQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy85Zi84My85ZjgzMDBlNWNjZDQxOGQyODNlNzJjMDdkMTg1MWYyNjlkYmQyY2E3YmFlNDljZWUyMTI4NTk2NWQ5YmViZTE0L2E5OTA4MjUzNzE1MDZjMTZiY2YwZTgxNjdiZjI0Y2NmODJmNjViYjZhMWRiY2JmY2YwNThkNzZmOWIxOTdlMzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=xAWxaXsy7pe2F%7EMyg%7EhwXwnpXV7USazanZNgTaUYWmz2sJDrDbNKXX-i2R5bKkKglq5a77akJFuns-SfhZP3lDgoTKwbSJf3M6j%7EMFnAZuXuLNgMtcv-CGjOaJKh9F%7Ee78FldqhVDpztWprq9s0piD-fD86b6sFBjaFWrsE8YgPRtjdmCVeSOfahL1b-uzj6jtzNeF8ayiBDY8rNERNbfXiP9u21POBGiYQxlDF5T%7EpK590O3i2iis5btgJ0xeevB8w7rAgCx4JJiZJ8LulCteQ4M5wM7RSET6T7Zddm%7EBu1z5%7E2s8PftqdEiIXa2w8SkgefSplDlt%7EnbyN25SneSg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-06-06 23:23:35--  https://cdn-lfs.huggingface.co/repos/9f/83/9f8300e5ccd418d283e72c07d1851f269dbd2ca7bae49cee21285965d9bebe14/a990825371506c16bcf0e8167bf24ccf82f65bb6a1dbcbfcf058d76f9b197e35?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27dvae.pth%3B+filename%3D%22dvae.pth%22%3B&Expires=1717975415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzk3NTQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy85Zi84My85ZjgzMDBlNWNjZDQxOGQyODNlNzJjMDdkMTg1MWYyNjlkYmQyY2E3YmFlNDljZWUyMTI4NTk2NWQ5YmViZTE0L2E5OTA4MjUzNzE1MDZjMTZiY2YwZTgxNjdiZjI0Y2NmODJmNjViYjZhMWRiY2JmY2YwNThkNzZmOWIxOTdlMzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=xAWxaXsy7pe2F%7EMyg%7EhwXwnpXV7USazanZNgTaUYWmz2sJDrDbNKXX-i2R5bKkKglq5a77akJFuns-SfhZP3lDgoTKwbSJf3M6j%7EMFnAZuXuLNgMtcv-CGjOaJKh9F%7Ee78FldqhVDpztWprq9s0piD-fD86b6sFBjaFWrsE8YgPRtjdmCVeSOfahL1b-uzj6jtzNeF8ayiBDY8rNERNbfXiP9u21POBGiYQxlDF5T%7EpK590O3i2iis5btgJ0xeevB8w7rAgCx4JJiZJ8LulCteQ4M5wM7RSET6T7Zddm%7EBu1z5%7E2s8PftqdEiIXa2w8SkgefSplDlt%7EnbyN25SneSg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.173.127, 18.155.173.61, 18.155.173.108, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.173.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 239873286 (229M) [binary/octet-stream]\n",
            "Saving to: ‘/content/ibibio-tts/experiments/dvae.pth’\n",
            "\n",
            "/content/ibibio-tts 100%[===================>] 228.76M   112MB/s    in 2.0s    \n",
            "\n",
            "2024-06-06 23:23:37 (112 MB/s) - ‘/content/ibibio-tts/experiments/dvae.pth’ saved [239873286/239873286]\n",
            "\n",
            "--2024-06-06 23:23:37--  https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.55, 18.164.174.118, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/57/08/5708d35b6a2408439b3511ccdaa992754f65f8e182278ecb9f654fc46a46f9fb/9c6651b9996df6cef6a1fc459738ae207ab60f902ec49b4d0623ca8ab6110d51?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27autoregressive.pth%3B+filename%3D%22autoregressive.pth%22%3B&Expires=1717973068&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzk3MzA2OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy81Ny8wOC81NzA4ZDM1YjZhMjQwODQzOWIzNTExY2NkYWE5OTI3NTRmNjVmOGUxODIyNzhlY2I5ZjY1NGZjNDZhNDZmOWZiLzljNjY1MWI5OTk2ZGY2Y2VmNmExZmM0NTk3MzhhZTIwN2FiNjBmOTAyZWM0OWI0ZDA2MjNjYThhYjYxMTBkNTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=JDYfzz2hjeqr%7EYkGjwRc-ZXHGf8uaZdrlaNvWMwNuKadxM-9i09Bz2RdlsCFVTjZHGMj2Gy6EaQT3ewevbYKGKnZSx75EZWo61gBrxaaXwEM%7EVBdZGhhYvDh1wTpAmYdToqnR-7JMxCJoof9cTu9YzsjVeEC%7EsAZPO5pTUz9wH3rEkbXkltMEompvPZFpVtEAO9gFbTDiQ8pE2ZBGyQ0OjdLmU1bm2BYq4fjFUXSo7mcU4H7F-aoX1ceRI7cUmr2cZf86tJRC9sGcoJXdQ9kGGyq9AY5D9ZHeVCA6revn63mCFu13ojQ8vZkwVeTkPHQ9190-Uj4JMTfyrGXNRy38w__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-06-06 23:23:37--  https://cdn-lfs.huggingface.co/repos/57/08/5708d35b6a2408439b3511ccdaa992754f65f8e182278ecb9f654fc46a46f9fb/9c6651b9996df6cef6a1fc459738ae207ab60f902ec49b4d0623ca8ab6110d51?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27autoregressive.pth%3B+filename%3D%22autoregressive.pth%22%3B&Expires=1717973068&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzk3MzA2OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy81Ny8wOC81NzA4ZDM1YjZhMjQwODQzOWIzNTExY2NkYWE5OTI3NTRmNjVmOGUxODIyNzhlY2I5ZjY1NGZjNDZhNDZmOWZiLzljNjY1MWI5OTk2ZGY2Y2VmNmExZmM0NTk3MzhhZTIwN2FiNjBmOTAyZWM0OWI0ZDA2MjNjYThhYjYxMTBkNTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=JDYfzz2hjeqr%7EYkGjwRc-ZXHGf8uaZdrlaNvWMwNuKadxM-9i09Bz2RdlsCFVTjZHGMj2Gy6EaQT3ewevbYKGKnZSx75EZWo61gBrxaaXwEM%7EVBdZGhhYvDh1wTpAmYdToqnR-7JMxCJoof9cTu9YzsjVeEC%7EsAZPO5pTUz9wH3rEkbXkltMEompvPZFpVtEAO9gFbTDiQ8pE2ZBGyQ0OjdLmU1bm2BYq4fjFUXSo7mcU4H7F-aoX1ceRI7cUmr2cZf86tJRC9sGcoJXdQ9kGGyq9AY5D9ZHeVCA6revn63mCFu13ojQ8vZkwVeTkPHQ9190-Uj4JMTfyrGXNRy38w__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.173.127, 18.155.173.61, 18.155.173.108, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.173.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1716988501 (1.6G) [application/zip]\n",
            "Saving to: ‘/content/ibibio-tts/experiments/autoregressive.pth’\n",
            "\n",
            "/content/ibibio-tts 100%[===================>]   1.60G   241MB/s    in 11s     \n",
            "\n",
            "2024-06-06 23:23:48 (154 MB/s) - ‘/content/ibibio-tts/experiments/autoregressive.pth’ saved [1716988501/1716988501]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure the waveform audio has a sampling rate of 22.05kHz\n",
        "Install librosa using the following command (automatically installs soundfile as well):\n",
        "pip install librosa"
      ],
      "metadata": {
        "id": "ui5jUdh7ST4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/drive/MyDrive/dataset/wav_split/wavs\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY8hZERevF1K",
        "outputId": "6767ce35-9c91-4318-fcef-c370467daa16"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def resample_wav_file(input_file, target_sampling_rate=22050):\n",
        "    # Load audio file\n",
        "    audio, sampling_rate = librosa.load(input_file, sr=None)\n",
        "\n",
        "    # Check if the sampling rate matches the target\n",
        "    if sampling_rate != target_sampling_rate:\n",
        "\n",
        "        # Resample audio to the target sampling rate\n",
        "        audio_resampled = librosa.resample(audio, orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
        "\n",
        "        # Overwrite the input file with the resampled audio\n",
        "        sf.write(input_file, audio_resampled, target_sampling_rate)"
      ],
      "metadata": {
        "id": "ja7Stce2QfY6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample all audio samples to 22.05kHz\n",
        "dataset_path = '/content/drive/MyDrive/dataset/wav_split/wavs'\n",
        "for wav_file in glob(dataset_path + \"*.wav\"):\n",
        "    resample_wav_file(input_file)"
      ],
      "metadata": {
        "id": "m5XZqSloQf9o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune THE AUTOREGRESSIVE MODEL"
      ],
      "metadata": {
        "id": "CpAZSlxqTRUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ibibio-tts/codes"
      ],
      "metadata": {
        "id": "j-7M-4bw4Ge8",
        "outputId": "f8ad077f-1ce8-4ba0-fa31-98f21446954a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ibibio-tts/codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ibibio-tts/codes/train.py -opt /content/ibibio-tts/experiments/custom_language_gpt.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQtEm55VQgLK",
        "outputId": "a5772fe3-0d1a-44eb-fbbd-21eb2de6d981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabled distributed training.\n",
            "Path already exists. Rename it to [/content/ibibio-tts/experiments/custom_language_gpt_archived_240606-232740]\n",
            "24-06-06 23:27:40.872 - INFO:   name: custom_language_gpt\n",
            "  model: extensibletrainer\n",
            "  scale: 1\n",
            "  gpu_ids: [0]\n",
            "  start_step: 0\n",
            "  checkpointing_enabled: True\n",
            "  fp16: False\n",
            "  use_8bit: True\n",
            "  wandb: True\n",
            "  use_tb_logger: False\n",
            "  datasets:[\n",
            "    train:[\n",
            "      name: train_dataset\n",
            "      n_workers: 8\n",
            "      batch_size: 128\n",
            "      mode: paired_voice_audio\n",
            "      path: /content/drive/MyDrive/dataset/wav_split/train.txt\n",
            "      fetcher_mode: ['lj']\n",
            "      phase: train\n",
            "      max_wav_length: 255995\n",
            "      max_text_length: 200\n",
            "      sample_rate: 22050\n",
            "      load_conditioning: True\n",
            "      num_conditioning_candidates: 2\n",
            "      conditioning_length: 44000\n",
            "      use_bpe_tokenizer: True\n",
            "      load_aligned_codes: False\n",
            "      tokenizer_vocab: /content/drive/MyDrive/dataset/custom_language_tokenizer.json\n",
            "      data_type: img\n",
            "    ]\n",
            "    val:[\n",
            "      name: val_dataset\n",
            "      n_workers: 1\n",
            "      batch_size: 64\n",
            "      mode: paired_voice_audio\n",
            "      path: /content/drive/MyDrive/dataset/wav_split/val.txt\n",
            "      fetcher_mode: ['lj']\n",
            "      phase: val\n",
            "      max_wav_length: 255995\n",
            "      max_text_length: 200\n",
            "      sample_rate: 22050\n",
            "      load_conditioning: True\n",
            "      num_conditioning_candidates: 2\n",
            "      conditioning_length: 44000\n",
            "      use_bpe_tokenizer: True\n",
            "      load_aligned_codes: False\n",
            "      tokenizer_vocab: /content/drive/MyDrive/dataset/custom_language_tokenizer.json\n",
            "      data_type: img\n",
            "    ]\n",
            "  ]\n",
            "  steps:[\n",
            "    gpt_train:[\n",
            "      training: gpt\n",
            "      loss_log_buffer: 500\n",
            "      optimizer: adamw\n",
            "      optimizer_params:[\n",
            "        lr: 1e-05\n",
            "        triton: False\n",
            "        weight_decay: 0.01\n",
            "        beta1: 0.9\n",
            "        beta2: 0.96\n",
            "      ]\n",
            "      clip_grad_eps: 4\n",
            "      injectors:[\n",
            "        paired_to_mel:[\n",
            "          type: torch_mel_spectrogram\n",
            "          mel_norm_file: /content/ibibio-tts/experiments/clips_mel_norms.pth\n",
            "          in: wav\n",
            "          out: paired_mel\n",
            "        ]\n",
            "        paired_cond_to_mel:[\n",
            "          type: for_each\n",
            "          subtype: torch_mel_spectrogram\n",
            "          mel_norm_file: /content/ibibio-tts/experiments/clips_mel_norms.pth\n",
            "          in: conditioning\n",
            "          out: paired_conditioning_mel\n",
            "        ]\n",
            "        to_codes:[\n",
            "          type: discrete_token\n",
            "          in: paired_mel\n",
            "          out: paired_mel_codes\n",
            "          dvae_config: /content/ibibio-tts/experiments/train_diffusion_vocoder_22k_level.yml\n",
            "        ]\n",
            "        paired_fwd_text:[\n",
            "          type: generator\n",
            "          generator: gpt\n",
            "          in: ['paired_conditioning_mel', 'padded_text', 'text_lengths', 'paired_mel_codes', 'wav_lengths']\n",
            "          out: ['loss_text_ce', 'loss_mel_ce', 'logits']\n",
            "        ]\n",
            "      ]\n",
            "      losses:[\n",
            "        text_ce:[\n",
            "          type: direct\n",
            "          weight: 0.01\n",
            "          key: loss_text_ce\n",
            "        ]\n",
            "        mel_ce:[\n",
            "          type: direct\n",
            "          weight: 1\n",
            "          key: loss_mel_ce\n",
            "        ]\n",
            "      ]\n",
            "    ]\n",
            "  ]\n",
            "  networks:[\n",
            "    gpt:[\n",
            "      type: generator\n",
            "      which_model_G: unified_voice2\n",
            "      kwargs:[\n",
            "        layers: 30\n",
            "        model_dim: 1024\n",
            "        heads: 16\n",
            "        max_text_tokens: 402\n",
            "        max_mel_tokens: 604\n",
            "        max_conditioning_inputs: 2\n",
            "        mel_length_compression: 1024\n",
            "        number_text_tokens: 256\n",
            "        number_mel_codes: 8194\n",
            "        start_mel_token: 8192\n",
            "        stop_mel_token: 8193\n",
            "        start_text_token: 255\n",
            "        train_solo_embeddings: False\n",
            "        use_mel_codes_as_input: True\n",
            "        checkpointing: True\n",
            "        tortoise_compat: True\n",
            "      ]\n",
            "    ]\n",
            "  ]\n",
            "  path:[\n",
            "    pretrain_model_gpt: /content/ibibio-tts/experiments/autoregressive.pth\n",
            "    strict_load: True\n",
            "    root: /content/ibibio-tts\n",
            "    experiments_root: /content/ibibio-tts/experiments/custom_language_gpt\n",
            "    models: /content/ibibio-tts/experiments/custom_language_gpt/models\n",
            "    training_state: /content/ibibio-tts/experiments/custom_language_gpt/training_state\n",
            "    log: /content/ibibio-tts/experiments/custom_language_gpt\n",
            "    val_images: /content/ibibio-tts/experiments/custom_language_gpt/val_images\n",
            "  ]\n",
            "  train:[\n",
            "    niter: 500\n",
            "    warmup_iter: -1\n",
            "    mega_batch_factor: 4\n",
            "    val_freq: 500\n",
            "    default_lr_scheme: MultiStepLR\n",
            "    gen_lr_steps: [500, 1000, 1400, 1800]\n",
            "    lr_gamma: 0.5\n",
            "    ema_enabled: False\n",
            "  ]\n",
            "  eval:[\n",
            "    pure: True\n",
            "  ]\n",
            "  logger:[\n",
            "    print_freq: 100\n",
            "    save_checkpoint_freq: 500\n",
            "    visuals: ['gen', 'mel']\n",
            "    visual_debug_rate: 500\n",
            "    is_mel_spectrogram: True\n",
            "    disable_state_saving: True\n",
            "  ]\n",
            "  upgrades:[\n",
            "    number_of_checkpoints_to_save: 0\n",
            "    number_of_states_to_save: 0\n",
            "  ]\n",
            "  is_train: True\n",
            "  dist: False\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maidysosu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ibibio-tts/experiments/custom_language_gpt/wandb/run-20240606_232742-kc5yplk7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgallant-oath-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aidysosu/custom_language_gpt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aidysosu/custom_language_gpt/runs/kc5yplk7\u001b[0m\n",
            "24-06-06 23:27:43.140 - INFO: Random seed: 8774\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "24-06-06 23:27:44.380 - INFO: Number of training data elements: 482, iters: 4\n",
            "24-06-06 23:27:44.380 - INFO: Total epochs needed: 125 for iters 500\n",
            "24-06-06 23:27:44.386 - INFO: Number of val images in [val_dataset]: 121\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Loading from ../experiments/dvae.pth\n",
            "24-06-06 23:27:56.797 - INFO: Network gpt structure: DataParallel, with parameters: 421,526,786\n",
            "24-06-06 23:27:56.797 - INFO: UnifiedVoice(\n",
            "  (conditioning_encoder): ConditioningEncoder(\n",
            "    (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (attn): Sequential(\n",
            "      (0): AttentionBlock(\n",
            "        (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
            "        (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
            "        (attention): QKVAttentionLegacy()\n",
            "        (x_proj): Identity()\n",
            "        (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
            "      )\n",
            "      (1): AttentionBlock(\n",
            "        (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
            "        (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
            "        (attention): QKVAttentionLegacy()\n",
            "        (x_proj): Identity()\n",
            "        (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
            "      )\n",
            "      (2): AttentionBlock(\n",
            "        (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
            "        (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
            "        (attention): QKVAttentionLegacy()\n",
            "        (x_proj): Identity()\n",
            "        (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
            "      )\n",
            "      (3): AttentionBlock(\n",
            "        (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
            "        (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
            "        (attention): QKVAttentionLegacy()\n",
            "        (x_proj): Identity()\n",
            "        (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
            "      )\n",
            "      (4): AttentionBlock(\n",
            "        (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
            "        (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
            "        (attention): QKVAttentionLegacy()\n",
            "        (x_proj): Identity()\n",
            "        (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
            "      )\n",
            "      (5): AttentionBlock(\n",
            "        (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
            "        (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
            "        (attention): QKVAttentionLegacy()\n",
            "        (x_proj): Identity()\n",
            "        (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (text_embedding): Embedding(256, 1024)\n",
            "  (mel_embedding): Embedding(8194, 1024)\n",
            "  (gpt): GPT2Model(\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-29): 30 x GPT2Block(\n",
            "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (mel_pos_embedding): LearnedPositionEmbeddings(\n",
            "    (emb): Embedding(608, 1024)\n",
            "  )\n",
            "  (text_pos_embedding): LearnedPositionEmbeddings(\n",
            "    (emb): Embedding(404, 1024)\n",
            "  )\n",
            "  (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (text_head): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (mel_head): Linear(in_features=1024, out_features=8194, bias=True)\n",
            ")\n",
            "24-06-06 23:27:56.797 - INFO: Loading model for [/content/ibibio-tts/experiments/autoregressive.pth]\n",
            "24-06-06 23:27:58.323 - INFO: Start training from epoch: 0, iter: 0\n",
            "  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "100% 3/3 [03:06<00:00, 62.20s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEmI8DPrTiNb",
        "outputId": "85268829-854e-4aee-f2ce-911fad13b149"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenizers\n",
        "print(tokenizers.__version__)\n"
      ],
      "metadata": {
        "id": "SjPOt6ZGUKXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd256e7-4849-48fa-9c69-ad034fa4d63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "\n",
        "\n",
        "\n",
        "def remove_extraneous_punctuation(word):\n",
        "    replacement_punctuation = {\n",
        "        '{': '(', '}': ')',\n",
        "        '[': '(', ']': ')',\n",
        "        '`': '\\'', '—': '-',\n",
        "        '—': '-', '`': '\\'',\n",
        "        'ʼ': '\\''\n",
        "    }\n",
        "    replace = re.compile(\"|\".join([re.escape(k) for k in sorted(replacement_punctuation, key=len, reverse=True)]), flags=re.DOTALL)\n",
        "    word = replace.sub(lambda x: replacement_punctuation[x.group(0)], word)\n",
        "    extraneous = re.compile(r'^[@#%_=\\$\\^&\\*\\+\\\\]$')\n",
        "    word = extraneous.sub('', word)\n",
        "    return word\n",
        "\n",
        "with open('transcriptions.txt', 'r', encoding='utf-8') as at:\n",
        "    ttsd = at.readlines()\n",
        "    allowed_characters_re = re.compile(r'^[a-zịñọʌ!:;\"/, \\-\\(\\)\\.\\'\\?ʼ]+$')\n",
        "\n",
        "    def preprocess_word(word, report=False):\n",
        "        word = remove_extraneous_punctuation(word)\n",
        "        if not bool(allowed_characters_re.match(word)):\n",
        "            if report and word:\n",
        "                print(f\"REPORTING: '{word}'\")\n",
        "            return ''\n",
        "        return word\n",
        "\n",
        "    def batch_iterator(batch_size=1000):\n",
        "        print(\"Processing ASR texts.\")\n",
        "        for i in range(0, len(ttsd), batch_size):\n",
        "            yield [preprocess_word(t, True) for t in ttsd[i:i+batch_size]]\n",
        "\n",
        "    trainer = BpeTrainer(special_tokens=['[STOP]', '[UNK]', '[SPACE]'], vocab_size=255)\n",
        "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    tokenizer.train_from_iterator(batch_iterator(), trainer, length=len(ttsd))\n",
        "    tokenizer.save('./custom_language_tokenizer.json')\n",
        "\n",
        "    # Save the tokenizer to hub\n",
        "    tokenizer.push_to_hub(repo_id='aidystark/ibibio-tokenizer')"
      ],
      "metadata": {
        "id": "QIXVBNHEav3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZF5QuOAf5Bp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}