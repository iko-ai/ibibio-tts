{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYzAk5hLQnvfoxMMMgXMVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iko-ai/ibibio-tts/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "519BayIw16w9",
        "outputId": "6d339e3f-4eb1-46cc-dcfe-90e13cbf9937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "CV6hrveq2eyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/drive/MyDrive/dataset/wav\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diC0lprL5UcB",
        "outputId": "75e77d7b-aa91-42be-f988-5cebddbeaba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "input_excel_path = '/content/metadata.xlsx'\n",
        "output_csv_path = '/content/drive/MyDrive/dataset/metadata.csv'\n",
        "\n",
        "# Read the Excel file\n",
        "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
        "\n",
        "# Save the dataframe as a CSV file\n",
        "df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Excel file has been successfully converted to CSV.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Xl15zB4vSr",
        "outputId": "e67949ef-48a7-4ac7-e828-1d5e301d5c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel file has been successfully converted to CSV.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "input_csv_path = '/content/drive/MyDrive/dataset/metadata.csv'\n",
        "input_wavs_dir = '/content/drive/MyDrive/dataset/wav'\n",
        "output_dir = '/content/drive/MyDrive/dataset/wav_split'\n",
        "train_txt_path = os.path.join(output_dir, 'train.txt')\n",
        "val_txt_path = os.path.join(output_dir, 'val.txt')"
      ],
      "metadata": {
        "id": "a5kFSaG65nPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Read the input CSV\n",
        "with open(input_csv_path, 'r') as csv_file:\n",
        "    reader = csv.DictReader(csv_file)\n",
        "    data = list(reader)\n",
        "\n",
        "# Shuffle the data\n",
        "random.shuffle(data)\n",
        "\n",
        "# Split the data into 80% training and 20% validation\n",
        "split_index = int(0.8 * len(data))\n",
        "train_data = data[:split_index]\n",
        "val_data = data[split_index:]\n",
        "\n",
        "# Function to write data to a text file\n",
        "def write_data(file_path, data):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for row in data:\n",
        "            filename = row['Filepath']\n",
        "            transcription = row['Transcription']\n",
        "            file.write(f\"wavs/{filename}|{transcription}\\n\")\n"
      ],
      "metadata": {
        "id": "SrqJKEJs2NA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the training and validation data to their respective files\n",
        "write_data(train_txt_path, train_data)\n",
        "write_data(val_txt_path, val_data)\n",
        "\n",
        "print(\"Dataset has been successfully split and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvpNLDAn5rSy",
        "outputId": "28366018-2073-423b-ddff-2f9528177627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has been successfully split and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/iko-ai/ibibio-texttospeech.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuIFNM9D5tC5",
        "outputId": "bcdf4bd6-f3da-4067-8136-caa101c0c74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ibibio-texttospeech'...\n",
            "remote: Enumerating objects: 16632, done.\u001b[K\n",
            "remote: Counting objects: 100% (401/401), done.\u001b[K\n",
            "remote: Compressing objects: 100% (201/201), done.\u001b[K\n",
            "remote: Total 16632 (delta 219), reused 351 (delta 199), pack-reused 16231\u001b[K\n",
            "Receiving objects: 100% (16632/16632), 12.15 MiB | 24.16 MiB/s, done.\n",
            "Resolving deltas: 100% (13332/13332), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd ibibio-texttospeech/codes\n",
        "#%cd codes\n",
        "%cd /content/ibibio-texttospeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg4QnjEu6Ngz",
        "outputId": "bb7138f4-4bad-45c7-d061-c25a818ad2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ibibio-texttospeech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.laxed.txt"
      ],
      "metadata": {
        "id": "QwsDLpEm6Swl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/Gatozu35/tortoise-tts/resolve/main/dvae.pth -O /content/ibibio-texttospeech/experiments/dvae.pth\n",
        "!wget https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth -O /content/ibibio-texttospeech/experiments/autoregressive.pth"
      ],
      "metadata": {
        "id": "qixhVDpCPilC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure the waveform audio has a sampling rate of 22.05kHz\n",
        "Install librosa using the following command (automatically installs soundfile as well):\n",
        "pip install librosa"
      ],
      "metadata": {
        "id": "ui5jUdh7ST4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def resample_wav_file(input_file, target_sampling_rate=22050):\n",
        "    # Load audio file\n",
        "    audio, sampling_rate = librosa.load(input_file, sr=None)\n",
        "\n",
        "    # Check if the sampling rate matches the target\n",
        "    if sampling_rate != target_sampling_rate:\n",
        "\n",
        "        # Resample audio to the target sampling rate\n",
        "        audio_resampled = librosa.resample(audio, orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
        "\n",
        "        # Overwrite the input file with the resampled audio\n",
        "        sf.write(input_file, audio_resampled, target_sampling_rate)"
      ],
      "metadata": {
        "id": "ja7Stce2QfY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample all audio samples to 22.05kHz\n",
        "dataset_path = '/content/drive/MyDrive/dataset/wav'\n",
        "for wav_file in glob(dataset_path + \"*.wav\"):\n",
        "    resample_wav_file(input_file)"
      ],
      "metadata": {
        "id": "m5XZqSloQf9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune THE AUTOREGRESSIVE MODEL"
      ],
      "metadata": {
        "id": "CpAZSlxqTRUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./codes/train.py -opt ./experiments/custom_language_gpt.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQtEm55VQgLK",
        "outputId": "547311a6-d449-4c8c-aa71-4f5235aab6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabled distributed training.\n",
            "Path already exists. Rename it to [/content/ibibio-texttospeech/experiments/custom_language_gpt_archived_240529-214842]\n",
            "24-05-29 21:48:42.504 - INFO:   name: custom_language_gpt\n",
            "  model: extensibletrainer\n",
            "  scale: 1\n",
            "  gpu_ids: [0]\n",
            "  start_step: 0\n",
            "  checkpointing_enabled: True\n",
            "  fp16: False\n",
            "  use_8bit: True\n",
            "  wandb: False\n",
            "  use_tb_logger: True\n",
            "  datasets:[\n",
            "    train:[\n",
            "      name: train_dataset\n",
            "      n_workers: 8\n",
            "      batch_size: 128\n",
            "      mode: paired_voice_audio\n",
            "      path: /content/drive/MyDrive/dataset/wav_split/train.txt\n",
            "      fetcher_mode: ['lj']\n",
            "      phase: train\n",
            "      max_wav_length: 255995\n",
            "      max_text_length: 200\n",
            "      sample_rate: 22050\n",
            "      load_conditioning: True\n",
            "      num_conditioning_candidates: 2\n",
            "      conditioning_length: 44000\n",
            "      use_bpe_tokenizer: True\n",
            "      load_aligned_codes: False\n",
            "      tokenizer_vocab: /content/drive/MyDrive/dataset/tokenizer.json\n",
            "      data_type: img\n",
            "    ]\n",
            "    val:[\n",
            "      name: val_dataset\n",
            "      n_workers: 1\n",
            "      batch_size: 64\n",
            "      mode: paired_voice_audio\n",
            "      path: /content/drive/MyDrive/dataset/wav_split/val.txt\n",
            "      fetcher_mode: ['lj']\n",
            "      phase: val\n",
            "      max_wav_length: 255995\n",
            "      max_text_length: 200\n",
            "      sample_rate: 22050\n",
            "      load_conditioning: True\n",
            "      num_conditioning_candidates: 2\n",
            "      conditioning_length: 44000\n",
            "      use_bpe_tokenizer: True\n",
            "      load_aligned_codes: False\n",
            "      tokenizer_vocab: /content/drive/MyDrive/dataset/tokenizer.json\n",
            "      data_type: img\n",
            "    ]\n",
            "  ]\n",
            "  steps:[\n",
            "    gpt_train:[\n",
            "      training: gpt\n",
            "      loss_log_buffer: 500\n",
            "      optimizer: adamw\n",
            "      optimizer_params:[\n",
            "        lr: 1e-05\n",
            "        triton: False\n",
            "        weight_decay: 0.01\n",
            "        beta1: 0.9\n",
            "        beta2: 0.96\n",
            "      ]\n",
            "      clip_grad_eps: 4\n",
            "      injectors:[\n",
            "        paired_to_mel:[\n",
            "          type: torch_mel_spectrogram\n",
            "          mel_norm_file: ../experiments/clips_mel_norms.pth\n",
            "          in: wav\n",
            "          out: paired_mel\n",
            "        ]\n",
            "        paired_cond_to_mel:[\n",
            "          type: for_each\n",
            "          subtype: torch_mel_spectrogram\n",
            "          mel_norm_file: ../experiments/clips_mel_norms.pth\n",
            "          in: conditioning\n",
            "          out: paired_conditioning_mel\n",
            "        ]\n",
            "        to_codes:[\n",
            "          type: discrete_token\n",
            "          in: paired_mel\n",
            "          out: paired_mel_codes\n",
            "          dvae_config: ../experiments/train_diffusion_vocoder_22k_level.yml\n",
            "        ]\n",
            "        paired_fwd_text:[\n",
            "          type: generator\n",
            "          generator: gpt\n",
            "          in: ['paired_conditioning_mel', 'padded_text', 'text_lengths', 'paired_mel_codes', 'wav_lengths']\n",
            "          out: ['loss_text_ce', 'loss_mel_ce', 'logits']\n",
            "        ]\n",
            "      ]\n",
            "      losses:[\n",
            "        text_ce:[\n",
            "          type: direct\n",
            "          weight: 0.01\n",
            "          key: loss_text_ce\n",
            "        ]\n",
            "        mel_ce:[\n",
            "          type: direct\n",
            "          weight: 1\n",
            "          key: loss_mel_ce\n",
            "        ]\n",
            "      ]\n",
            "    ]\n",
            "  ]\n",
            "  networks:[\n",
            "    gpt:[\n",
            "      type: generator\n",
            "      which_model_G: unified_voice2\n",
            "      kwargs:[\n",
            "        layers: 30\n",
            "        model_dim: 1024\n",
            "        heads: 16\n",
            "        max_text_tokens: 402\n",
            "        max_mel_tokens: 604\n",
            "        max_conditioning_inputs: 2\n",
            "        mel_length_compression: 1024\n",
            "        number_text_tokens: 256\n",
            "        number_mel_codes: 8194\n",
            "        start_mel_token: 8192\n",
            "        stop_mel_token: 8193\n",
            "        start_text_token: 255\n",
            "        train_solo_embeddings: False\n",
            "        use_mel_codes_as_input: True\n",
            "        checkpointing: True\n",
            "        tortoise_compat: True\n",
            "      ]\n",
            "    ]\n",
            "  ]\n",
            "  path:[\n",
            "    pretrain_model_gpt: ../experiments/autoregressive.pth\n",
            "    strict_load: True\n",
            "    root: /content/ibibio-texttospeech\n",
            "    experiments_root: /content/ibibio-texttospeech/experiments/custom_language_gpt\n",
            "    models: /content/ibibio-texttospeech/experiments/custom_language_gpt/models\n",
            "    training_state: /content/ibibio-texttospeech/experiments/custom_language_gpt/training_state\n",
            "    log: /content/ibibio-texttospeech/experiments/custom_language_gpt\n",
            "    val_images: /content/ibibio-texttospeech/experiments/custom_language_gpt/val_images\n",
            "  ]\n",
            "  train:[\n",
            "    niter: 500\n",
            "    warmup_iter: -1\n",
            "    mega_batch_factor: 4\n",
            "    val_freq: 500\n",
            "    default_lr_scheme: MultiStepLR\n",
            "    gen_lr_steps: [500, 1000, 1400, 1800]\n",
            "    lr_gamma: 0.5\n",
            "    ema_enabled: False\n",
            "  ]\n",
            "  eval:[\n",
            "    pure: True\n",
            "  ]\n",
            "  logger:[\n",
            "    print_freq: 100\n",
            "    save_checkpoint_freq: 500\n",
            "    visuals: ['gen', 'mel']\n",
            "    visual_debug_rate: 500\n",
            "    is_mel_spectrogram: True\n",
            "    disable_state_saving: True\n",
            "  ]\n",
            "  upgrades:[\n",
            "    number_of_checkpoints_to_save: 0\n",
            "    number_of_states_to_save: 0\n",
            "  ]\n",
            "  is_train: True\n",
            "  dist: False\n",
            "\n",
            "2024-05-29 21:48:43.014254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-29 21:48:43.014311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-29 21:48:43.016241: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-29 21:48:43.026696: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-29 21:48:44.748176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "24-05-29 21:48:46.600 - INFO: Random seed: 2986\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "24-05-29 21:48:47.912 - INFO: Number of training data elements: 482, iters: 4\n",
            "24-05-29 21:48:47.912 - INFO: Total epochs needed: 125 for iters 500\n",
            "24-05-29 21:48:47.917 - INFO: Number of val images in [val_dataset]: 121\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ibibio-texttospeech/./codes/train.py\", line 398, in <module>\n",
            "    trainer.init(args.opt, opt, args.launcher)\n",
            "  File \"/content/ibibio-texttospeech/./codes/train.py\", line 146, in init\n",
            "    self.model = ExtensibleTrainer(opt)\n",
            "  File \"/content/ibibio-texttospeech/codes/trainer/ExtensibleTrainer.py\", line 86, in __init__\n",
            "    new_net = networks.create_model(opt, net, self.netsG).to(self.device)\n",
            "  File \"/content/ibibio-texttospeech/codes/trainer/networks.py\", line 70, in create_model\n",
            "    raise CreateModelError(which_model, list(registered_fns.keys()))\n",
            "trainer.networks.CreateModelError: Could not find the specified model name: unified_voice2. Tip: If your model is in a subdirectory, that directory must contain an __init__.py to be scanned. Available models:[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEmI8DPrTiNb",
        "outputId": "ffd94d62-fd30-4c1a-d185-ec78869b1285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjPOt6ZGUKXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}